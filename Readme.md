Efficient Memory Management for Large Language Model Serving with PagedAttention
https://arxiv.org/abs/2309.06180

Attention Is All You Need
https://arxiv.org/abs/1706.03762

flash attention
https://arxiv.org/abs/2205.14135

FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning
https://arxiv.org/abs/2307.08691
